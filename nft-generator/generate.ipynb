{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image \n",
    "from IPython.display import display \n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each image is made up a series of traits\n",
    "# The weightings for each trait drive the rarity and add up to 100%\n",
    "\n",
    "background = [\"bg1\", \"bg2\", \"bg3\", \"bg4\"] \n",
    "background_weights = [25, 25, 25, 25]\n",
    "\n",
    "body = [\"body1\", \"body2\", \"body3\"] \n",
    "body_weights = [33, 34, 33]\n",
    "\n",
    "cap = [\"cap1\", \"cap2\", \"cap3\"] \n",
    "cap_weights = [33, 34, 33]\n",
    "\n",
    "# Dictionary variable for each trait. \n",
    "# Eech trait corresponds to its file name\n",
    "\n",
    "background_files = {\n",
    "    \"bg1\": \"bg1\",\n",
    "    \"bg2\": \"bg2\",\n",
    "    \"bg3\": \"bg3\",\n",
    "    \"bg4\": \"bg4\",\n",
    "}\n",
    "\n",
    "body_files = {\n",
    "    \"body1\": \"body1\",\n",
    "    \"body2\": \"body2\",\n",
    "    \"body3\": \"body3\",\n",
    "}\n",
    "\n",
    "cap_files = {\n",
    "    \"cap1\": \"cap1\",\n",
    "    \"cap2\": \"cap2\",\n",
    "    \"cap3\": \"cap3\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Traits\n",
    "\n",
    "TOTAL_IMAGES = 36 # Number of random unique images we want to generate\n",
    "\n",
    "all_images = [] \n",
    "\n",
    "# A recursive function to generate unique image combinations\n",
    "def create_new_image():\n",
    "    \n",
    "    new_image = {} #\n",
    "\n",
    "    # For each trait category, select a random trait based on the weightings \n",
    "    new_image [\"Background\"] = random.choices(background, background_weights)[0]\n",
    "    new_image [\"body\"] = random.choices(body, body_weights)[0]\n",
    "    new_image [\"cap\"] = random.choices(cap, cap_weights)[0]\n",
    "    \n",
    "    if new_image in all_images:\n",
    "        return create_new_image()\n",
    "    else:\n",
    "        return new_image\n",
    "    \n",
    "    \n",
    "# Generate the unique combinations based on trait weightings\n",
    "for i in range(TOTAL_IMAGES): \n",
    "    \n",
    "    new_trait_image = create_new_image()\n",
    "    \n",
    "    all_images.append(new_trait_image)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns true if all images are unique\n",
    "def all_images_unique(all_images):\n",
    "    seen = list()\n",
    "    return not any(i in seen or seen.append(i) for i in all_images)\n",
    "\n",
    "print(\"Are all images unique?\", all_images_unique(all_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add token Id to each image\n",
    "i = 0\n",
    "for item in all_images:\n",
    "    item[\"tokenId\"] = i\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Trait Counts\n",
    "\n",
    "background_count = {}\n",
    "for item in background:\n",
    "    background_count[item] = 0\n",
    "    \n",
    "body_count = {}\n",
    "for item in body:\n",
    "    body_count[item] = 0\n",
    "\n",
    "cap_count = {}\n",
    "for item in cap:\n",
    "    cap_count[item] = 0\n",
    "\n",
    "for image in all_images:\n",
    "    background_count[image[\"Background\"]] += 1\n",
    "    body_count[image[\"body\"]] += 1\n",
    "    cap_count[image[\"cap\"]] += 1\n",
    "    \n",
    "print(background_count)\n",
    "print(body_count)\n",
    "print(cap_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Generate Metadata for all Traits \n",
    "METADATA_FILE_NAME = './metadata/all-traits.json'; \n",
    "with open(METADATA_FILE_NAME, 'w') as outfile:\n",
    "    json.dump(all_images, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "    \n",
    "#### Generate Images    \n",
    "for item in all_images:\n",
    "\n",
    "    im1 = Image.open(f'./trait-layers/backgrounds/{background_files[item[\"Background\"]]}.png').convert('RGBA')\n",
    "    im2 = Image.open(f'./trait-layers/bodys/{body_files[item[\"body\"]]}.png').convert('RGBA')\n",
    "    im3 = Image.open(f'./trait-layers/caps/{cap_files[item[\"cap\"]]}.png').convert('RGBA')\n",
    "\n",
    "    #Create each composite\n",
    "    com1 = Image.alpha_composite(im1, im2)\n",
    "    com2 = Image.alpha_composite(com1, im3)\n",
    "\n",
    "    #Convert to RGB\n",
    "    rgb_im = com2.convert('RGB')\n",
    "    file_name = str(item[\"tokenId\"]) + \".png\"\n",
    "    rgb_im.save(\"./images/\" + file_name)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Generate Metadata for each Image    \n",
    "\n",
    "f = open('./metadata/all-traits.json',) \n",
    "data = json.load(f)\n",
    "\n",
    "\n",
    "IMAGES_BASE_URI = \"ADD_IMAGES_BASE_URI_HERE\"\n",
    "PROJECT_NAME = \"ADD_PROJECT_NAME_HERE\"\n",
    "\n",
    "def getAttribute(key, value):\n",
    "    return {\n",
    "        \"trait_type\": key,\n",
    "        \"value\": value\n",
    "    }\n",
    "for i in data:\n",
    "    token_id = i['tokenId']\n",
    "    token = {\n",
    "        \"image\": IMAGES_BASE_URI + str(token_id) + '.png',\n",
    "        \"tokenId\": token_id,\n",
    "        \"name\": PROJECT_NAME + ' ' + str(token_id),\n",
    "        \"attributes\": []\n",
    "    }\n",
    "    token[\"attributes\"].append(getAttribute(\"Background\", i[\"Background\"]))\n",
    "    token[\"attributes\"].append(getAttribute(\"body\", i[\"body\"]))\n",
    "    token[\"attributes\"].append(getAttribute(\"cap\", i[\"cap\"]))\n",
    "\n",
    "    with open('./metadata/' + str(token_id), 'w') as outfile:\n",
    "        json.dump(token, outfile, indent=4)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3d65f8beab89bca824669a8319117cabe601d9aca9a71aad8efeb42336828120"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
